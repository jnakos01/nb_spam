{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2025 Semester 1\n",
    "\n",
    "## Assignment 1: Scam detection with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Student ID(s):**     `1462474`\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, GRAPHS, AND FIGURES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).** Results, figures, etc. which appear in this file but are NOT included in your report will not be marked.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised model training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.260583Z",
     "start_time": "2025-04-08T15:50:09.257086Z"
    }
   },
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Read in supervised training dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.312308Z",
     "start_time": "2025-04-08T15:50:09.302453Z"
    }
   },
   "cell_type": "code",
   "source": "sms_df = pd.read_csv('sms_supervised_train.csv')",
   "outputs": [],
   "execution_count": 1118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reformat text to help with tokenising"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.323894Z",
     "start_time": "2025-04-08T15:50:09.318294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensures data types are as intended and no nulls\n",
    "def preprocess_data(df):\n",
    "    df['textPreprocessed'] = df['textPreprocessed'].astype(str)\n",
    "    df = df.dropna(subset=['textPreprocessed'])\n",
    "    df['class'] = df['class'].astype(int)\n",
    "    return df\n",
    "\n",
    "sms_df = preprocess_data(sms_df)"
   ],
   "outputs": [],
   "execution_count": 1119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Build vocabulary list"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.369394Z",
     "start_time": "2025-04-08T15:50:09.362791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define vocab list (set for build efficiency)\n",
    "vocab_set = set()\n",
    "\n",
    "# For each row in the dataset, split text into words and add them to the vocab set\n",
    "# Convert to a list at the end\n",
    "def create_vocab_list(df):\n",
    "    vocab_set = set()\n",
    "    for text in df['textPreprocessed']:\n",
    "        words = text.split()\n",
    "        vocab_set.update(words)\n",
    "    return list(vocab_set)\n",
    "\n",
    "# Create vocab list\n",
    "vocab_list = create_vocab_list(sms_df)\n"
   ],
   "outputs": [],
   "execution_count": 1120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Build count matrix"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.435108Z",
     "start_time": "2025-04-08T15:50:09.409178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates a count matrix where each row represents a text instance\n",
    "# Columns represent the words in the vocab list.\n",
    "# Returns the matrix and a dictionary mapping words to their index in the vocab list\n",
    "def build_count_matrix(df, vocab_list):\n",
    "    # Initialise empty count matrix\n",
    "    count_matrix = np.zeros((df.shape[0], len(vocab_list)))\n",
    "    # Create dictionary mapping words to their index in the vocab list\n",
    "    vocab_dict = {word: i for i, word in enumerate(vocab_list)}\n",
    "    for index, text in df['textPreprocessed'].items():\n",
    "        for word in text.split():\n",
    "            # If the word is in the vocab list, increment its count in the matrix\n",
    "            if word in vocab_dict:\n",
    "                word_index = vocab_dict.get(word)\n",
    "                count_matrix[index][word_index] += 1\n",
    "    return count_matrix, vocab_dict\n",
    "\n",
    "# Build count matrix\n",
    "count_matrix,vocab_dict = build_count_matrix(sms_df, vocab_list)"
   ],
   "outputs": [],
   "execution_count": 1121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute the prior probability of each class:\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.475064Z",
     "start_time": "2025-04-08T15:50:09.470127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the prior probability of each class given the dataframe\n",
    "def calculate_priors(df):\n",
    "    n_rows = df.shape[0]\n",
    "    # Count the number of instances in each class\n",
    "    n_c0 = df[df['class'] == 0].shape[0]\n",
    "    n_c1 = df[df['class'] == 1].shape[0]\n",
    "    # Calculate the prior probability of each class\n",
    "    p_c0 = n_c0 / n_rows\n",
    "    p_c1 = n_c1 / n_rows\n",
    "    return [p_c0, p_c1]\n",
    "\n",
    "# Calculate priors\n",
    "priors = calculate_priors(sms_df)\n",
    "p_c0 = priors[0]\n",
    "p_c1 = priors[1]\n",
    "\n",
    "# Answer to question 1 in our report\n",
    "print(f\"Our two priors are p_c0 = {p_c0}\\nand p_c1 = {p_c1} \")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our two priors are p_c0 = 0.8\n",
      "and p_c1 = 0.2 \n"
     ]
    }
   ],
   "execution_count": 1122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Find the probability of each word appearing in a message from each class (likelihood)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.524695Z",
     "start_time": "2025-04-08T15:50:09.511011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we need to find the number of times each word appears in each class\n",
    "\n",
    "''' Counts the number of times each word appears in a given class\n",
    "    returns an list of counts '''\n",
    "def count_words_in_class(class_num, train_df, count_matrix):\n",
    "    # Find the indexes of the rows in the count matrix that belong to the given class\n",
    "    index_list = np.where(train_df['class'] == class_num)[0]\n",
    "    # Get the count matrix for the given class (only shows rows where we classify as class_num)\n",
    "    class_count_matrix = count_matrix[index_list]\n",
    "    # Sums the word counts across all text instances for the class\n",
    "    count_list = class_count_matrix.sum(axis=0)\n",
    "    return count_list\n",
    "\n",
    "# Class 0 count\n",
    "count_c0 = count_words_in_class(0, sms_df, count_matrix)\n",
    "\n",
    "# Class 1 count\n",
    "count_c1 = count_words_in_class(1, sms_df, count_matrix)\n"
   ],
   "outputs": [],
   "execution_count": 1123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.567225Z",
     "start_time": "2025-04-08T15:50:09.559541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We will use laplace smoothing to ensure every event has a non-zero probability\n",
    "# Since we have sparse data (more on report)\n",
    "\n",
    "# Laplace smoothing value\n",
    "alpha = 1\n",
    "\n",
    "# Laplace function returns the conditional probability of a word given a class\n",
    "# with laplace smoothing\n",
    "def laplace(count, alpha, total, v):\n",
    "    return (count+alpha) / (total + v*alpha)\n",
    "\n",
    "# Calculates the likelihoods p_(c,i) of word i appearing in a given class c\n",
    "# returns the probability lists for each word in the vocab list and each class\n",
    "def calculate_likelihoods(count_c0, count_c1, vocab_dict, alpha=1):\n",
    "    # Initialise empty lists to store the likelihoods\n",
    "    class_0_c = []\n",
    "    class_1_c = []\n",
    "    # Calculate total count of words in each class\n",
    "    total_c0 = count_c0.sum()\n",
    "    total_c1 = count_c1.sum()\n",
    "    # Find the length of the vocab list\n",
    "    V = len(vocab_dict)\n",
    "    # For each class calculate the likelihood list\n",
    "    for word, index in vocab_dict.items():\n",
    "        count = count_c0[index]\n",
    "        # Find prob using laplace smoothing\n",
    "        p_ci = laplace(count, alpha, total_c0, V)\n",
    "        class_0_c.append(p_ci)\n",
    "    for word, index in vocab_dict.items():\n",
    "        count = count_c1[index]\n",
    "        # Find prob using laplace smoothing\n",
    "        p_ci = laplace(count, alpha, total_c1, V)\n",
    "        class_1_c.append(p_ci)\n",
    "    return class_0_c, class_1_c\n",
    "\n",
    "# Find the likelihoods for each class\n",
    "class_0_c, class_1_c = calculate_likelihoods(count_c0, count_c1, vocab_dict, alpha)\n",
    "\n",
    "\n",
    "# Check probabilities sum to roughly one\n",
    "print(sum(class_1_c))\n",
    "print(sum(class_0_c))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999999978\n",
      "1.0000000000000058\n"
     ]
    }
   ],
   "execution_count": 1124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Further supervised model training questions for report"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.617897Z",
     "start_time": "2025-04-08T15:50:09.610101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Question 2\n",
    "# Find the most probable words in each class\n",
    "\n",
    "# We find the 10 most probable words by sorting the probabilities list\n",
    "# and finding their indexes in the original vocab list\n",
    "\n",
    "'''Finds and returns the n most probable words in a given class\n",
    "    returns a list in order of probability (descending) and a list\n",
    "     containing their probability values'''\n",
    "def find_n_most_probable(n, class_num):\n",
    "    # Find the count list for the given class\n",
    "    if class_num == 0:\n",
    "        prob_list = class_0_c\n",
    "    elif class_num == 1:\n",
    "        prob_list = class_1_c\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    # Sort the list and get the indexes of the n most probable words\n",
    "    sorted_indexes = np.argsort(prob_list)[-n:][::-1]\n",
    "\n",
    "    sorted_probs = np.sort(prob_list)[-n:][::-1]\n",
    "\n",
    "    # Get the words from our vocab list using the indexes\n",
    "    most_probable_words = [vocab_list[i] for i in sorted_indexes]\n",
    "\n",
    "    return most_probable_words, sorted_probs\n",
    "\n",
    "\n",
    "# Find the 10 most probable words in class 0\n",
    "print(\"Most probable words in class 0:\", find_n_most_probable(10, 0)[0])\n",
    "\n",
    "# List their probability values\n",
    "print(\"Probability values for class 0:\", find_n_most_probable(10, 0)[1])\n",
    "\n",
    "# Find the 10 most probable words in class 1\n",
    "print(\"Most probable words in class 1:\", find_n_most_probable(10, 1)[0])\n",
    "print(\"Probability values for class 1:\", find_n_most_probable(10, 1)[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable words in class 0: ['.', ',', '?', 'u', '...', '!', '..', ';', '&', 'go']\n",
      "Probability values for class 0: [0.07930378 0.02602418 0.02557645 0.0189165  0.0187486  0.01718155\n",
      " 0.01494291 0.013152   0.01309604 0.01113723]\n",
      "Most probable words in class 1: ['.', '!', ',', 'call', '£', 'free', '/', '2', '&', '?']\n",
      "Probability values for class 1: [0.05652174 0.02434783 0.02347826 0.02054348 0.01391304 0.01054348\n",
      " 0.00913043 0.00880435 0.00869565 0.00847826]\n"
     ]
    }
   ],
   "execution_count": 1125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Question 3: Finding the most predictive words\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.666351Z",
     "start_time": "2025-04-08T15:50:09.659932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the probability ratio of a word occurring in class 0 vs class 1\n",
    "class_0_c = np.array(class_0_c)\n",
    "class_1_c = np.array(class_1_c)\n",
    "p_ratio_non_mal = class_0_c/class_1_c\n",
    "\n",
    "# We don't have to worry about dividing by zero as we have already applied laplace smoothing\n",
    "\n",
    "# Find the 10 most strongly predictive words of the non-malicious class\n",
    "sorted_c0_div_c1 = np.argsort(p_ratio_non_mal)[-10:][::-1]\n",
    "most_predictive_words_non_mal = [vocab_list[i] for i in sorted_c0_div_c1]\n",
    "non_scam_ratios = np.sort(p_ratio_non_mal)[-10:][::-1]\n",
    "\n",
    "# Find the 10 most strongly predictive words of the malicious class\n",
    "p_ratio_mal = class_1_c/class_0_c\n",
    "sorted_c1_div_c0 = np.argsort(p_ratio_mal)[-10:][::-1]\n",
    "most_predictive_words_mal = [vocab_list[i] for i in sorted_c1_div_c0]\n",
    "scam_ratios = np.sort(p_ratio_mal)[-10:][::-1]\n",
    "\n",
    "# Print the most predictive words of the non-malicious class\n",
    "print(\"The most predictive words of the non-malicious class are:\", most_predictive_words_non_mal)\n",
    "print(\"The associated probability ratios are:\", non_scam_ratios)\n",
    "\n",
    "\n",
    "\n",
    "# Print the most predictive words of the malicious class\n",
    "print(\"The most predictive words of the malicious class are:\", most_predictive_words_mal)\n",
    "print(\"The associated probability ratios are:\", scam_ratios)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most predictive words of the non-malicious class are: [';', '...', 'gt', 'lt', ':)', 'ü', 'lor', 'ok', 'hope', 'd']\n",
      "The associated probability ratios are: [60.49921648 57.49570928 54.06312962 53.54824267 47.88448623 31.92299082\n",
      " 28.83366913 24.71457354 24.71457354 21.1103649 ]\n",
      "The most predictive words of the malicious class are: ['prize', 'tone', '£', 'select', 'claim', 'paytm', 'code', 'award', 'won', '18']\n",
      "The associated probability ratios are: [99.05086957 64.09173913 49.71965217 46.61217391 45.96478261 36.90130435\n",
      " 34.95913043 32.04586957 31.07478261 29.1326087 ]\n"
     ]
    }
   ],
   "execution_count": 1126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Supervised model evaluation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting the labels of our test set"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.720548Z",
     "start_time": "2025-04-08T15:50:09.712420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in our test dataset\n",
    "test_df = pd.read_csv('sms_test.csv')\n"
   ],
   "outputs": [],
   "execution_count": 1127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.769397Z",
     "start_time": "2025-04-08T15:50:09.763435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the same preprocessing steps as before\n",
    "# Ensure all values in the column are strings\n",
    "test_df['textPreprocessed'] = test_df['textPreprocessed'].astype(str)\n",
    "\n",
    "# Ensure no null values affect tokenising\n",
    "# Find num rows\n",
    "test_rows = test_df.shape[0]\n",
    "print(\"Number of entries before dropping null values: \", test_rows)\n",
    "test_df = test_df.dropna(subset=['textPreprocessed'])\n",
    "print(\"Number of entries before after dropping null values: \", test_rows)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries before dropping null values:  1000\n",
      "Number of entries before after dropping null values:  1000\n"
     ]
    }
   ],
   "execution_count": 1128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.828626Z",
     "start_time": "2025-04-08T15:50:09.811308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each test instance, compute a count vector\n",
    "# which represents the number of times each word in the vocab list appears\n",
    "# This will be in the form of an N_test x V matrix\n",
    "def build_test_count_matrix(test_df, vocab_list, vocab_dict):\n",
    "    # Initialise empty count matrix\n",
    "    test_count_matrix = np.zeros((test_df.shape[0], len(vocab_list)))\n",
    "    # Counters and sets for question 2\n",
    "    unique_words_in_vocab = set()\n",
    "    unique_words_not_in_vocab = set()\n",
    "    num_test_words_in_vocab = 0\n",
    "    num_test_words_not_in_vocab = 0\n",
    "\n",
    "    # Add words that exist in our vocab to the new count matrix for each row in the data\n",
    "    for index, text in enumerate(test_df['textPreprocessed']):\n",
    "        for word in text.split():\n",
    "            if word in vocab_dict:\n",
    "                word_index = vocab_dict.get(word)\n",
    "                test_count_matrix[index][word_index] += 1\n",
    "                unique_words_in_vocab.add(word)\n",
    "                num_test_words_in_vocab += 1\n",
    "            else:\n",
    "                unique_words_not_in_vocab.add(word)\n",
    "                num_test_words_not_in_vocab += 1\n",
    "\n",
    "    return test_count_matrix, num_test_words_in_vocab, num_test_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab\n",
    "\n",
    "\n",
    "\n",
    "# Build the test count matrix\n",
    "test_count_matrix, num_test_words_in_vocab, num_test_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab = build_test_count_matrix(test_df, vocab_list, vocab_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of unique words and in the vocab list and test (for question 2)\n",
    "num_unique_words_in_vocab = len(unique_words_in_vocab)\n",
    "num_unique_words_not_in_vocab = len(unique_words_not_in_vocab)\n",
    "num_test_words_total = num_test_words_in_vocab + num_test_words_not_in_vocab\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:09.872763Z",
     "start_time": "2025-04-08T15:50:09.864531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if all test instances contain words from the vocab list\n",
    "# If an instance contains no words from the vocab list, we won't classify it\n",
    "\n",
    "for row in test_count_matrix:\n",
    "    if row.sum() == 0:\n",
    "        print(\"Found a row with no words from the vocab list\")\n",
    "        print(row)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "No test items skipped as this code does not output any rows (refer to q2 below)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute the posterior probability of each class given the observed word count"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.311310Z",
     "start_time": "2025-04-08T15:50:09.909495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each test instance, we compute the posterior probability of observing each\n",
    "# word given the class label\n",
    "def calc_posterior(count_matrix, likelihoods_list, label_index, priors):\n",
    "    # Initialise empty list to store posterior probabilities\n",
    "    posterior_probs = []\n",
    "    prior_value = priors[label_index]\n",
    "\n",
    "    # For each test instance\n",
    "    for row in count_matrix:\n",
    "        # Initialise posterior probability\n",
    "        posterior = np.log(prior_value)\n",
    "\n",
    "        # For each word in the vocab list\n",
    "        for i, word_freq in enumerate(row):\n",
    "            if word_freq > 0:\n",
    "                # Get the likelihood of the word given the class label\n",
    "                likelihood_value = likelihoods_list[i]\n",
    "\n",
    "                # Take the log of this value to combat overflow\n",
    "                log_likelihood_value = np.log(likelihood_value)\n",
    "\n",
    "\n",
    "                # Update the posterior probability\n",
    "                posterior += (log_likelihood_value * word_freq)\n",
    "\n",
    "\n",
    "        # Find the log multinomial coefficient\n",
    "        # Using log gamma function to avoid overflow\n",
    "        log_multinomial_coefficient = (\n",
    "            math.lgamma(row.sum() + 1) - np.sum([math.lgamma(c + 1) for c in row])\n",
    "        )\n",
    "\n",
    "        posterior += log_multinomial_coefficient\n",
    "\n",
    "        # Take the exponent of the posterior probability\n",
    "        posterior = np.exp(posterior)\n",
    "\n",
    "\n",
    "        # Add the posterior probability to our list\n",
    "        posterior_probs.append(posterior)\n",
    "    return posterior_probs\n",
    "\n",
    "# Class 0 posterior\n",
    "c0_posterior = calc_posterior(test_count_matrix, class_0_c, 0, priors)\n",
    "\n",
    "# Class 1 posterior\n",
    "\n",
    "c1_posterior = calc_posterior(test_count_matrix, class_1_c, 1, priors)\n",
    "\n",
    "\n",
    "print(max(c1_posterior))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011304347826086959\n"
     ]
    }
   ],
   "execution_count": 1131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Predict the labels of each test instance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.353067Z",
     "start_time": "2025-04-08T15:50:11.348764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Predicts the labels of each test instance using the posterior probabilities '''\n",
    "def predict_nb(c0_posterior, c1_posterior):\n",
    "\n",
    "    # Using our previously calculated posterior probabilities:\n",
    "\n",
    "    # Find argmax for each instance\n",
    "    argmax_labels = []\n",
    "    associated_probs = []\n",
    "\n",
    "    for post_prob_0, post_prob_1 in zip(c0_posterior, c1_posterior):\n",
    "        # Find the maximum posterior probability\n",
    "        if post_prob_0 >= post_prob_1:\n",
    "            associated_probs.append(post_prob_0)\n",
    "            argmax_labels.append(0)\n",
    "\n",
    "        # Otherwise if probabilities are less we classify as 1\n",
    "        else:\n",
    "            associated_probs.append(post_prob_1)\n",
    "            argmax_labels.append(1)\n",
    "\n",
    "    return argmax_labels, associated_probs\n",
    "\n",
    "\n",
    "# Run on our dataset\n",
    "pred_labels, probs = predict_nb(c0_posterior, c1_posterior)\n",
    "\n",
    "print(pred_labels[1:20])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "execution_count": 1132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Find the accuracy of our model (Q1)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.399853Z",
     "start_time": "2025-04-08T15:50:11.394327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Overall accuracy of our classifier\n",
    "\n",
    "def get_accuracy(labels, true_labels):\n",
    "    # Find the number of correct predictions\n",
    "    num_correct = np.sum(labels == true_labels)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = num_correct / len(true_labels)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_df['class'].values\n",
    "\n",
    "# Prints the accuracy, confusion matrix, precision and recall\n",
    "# of our model's predictions\n",
    "def model_eval(true_labels, pred_labels):\n",
    "    accuracy = get_accuracy(true_labels, pred_labels)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix = np.zeros((2, 2), dtype=int)\n",
    "    # Fill the confusion matrix\n",
    "    for true, predicted in zip(true_labels, pred_labels):\n",
    "        confusion_matrix[true][predicted] += 1\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "    TN = confusion_matrix[0, 0]\n",
    "    FP = confusion_matrix[0, 1]\n",
    "    FN = confusion_matrix[1, 0]\n",
    "    TP = confusion_matrix[1, 1]\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Evaluate our model\n",
    "model_eval(true_labels, pred_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n",
      "Confusion Matrix:\n",
      " [[785  15]\n",
      " [ 10 190]]\n",
      "Precision: 0.93\n",
      "Recall: 0.95\n"
     ]
    }
   ],
   "execution_count": 1133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### How often we encountered out of vocab words (Q2)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.444061Z",
     "start_time": "2025-04-08T15:50:11.439870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_vocab_proportions(num_unique_words_not_in_vocab, num_unique_words_in_vocab, num_test_words_in_vocab, num_test_words_total):\n",
    "    # Proportion of unique words in the test set that were not in the vocab list\n",
    "    prop_unique_not_in_vocab = num_unique_words_not_in_vocab / (num_unique_words_not_in_vocab + num_unique_words_in_vocab)\n",
    "    prop_unique_in_vocab = 1 - prop_unique_not_in_vocab\n",
    "\n",
    "    print(f\"Proportion of unique words in vocab: {prop_unique_in_vocab}\")\n",
    "    print(f\"Proportion of unique words not in vocab: {prop_unique_not_in_vocab}\")\n",
    "\n",
    "    # Proportion of words in the test set that were not in the vocab list\n",
    "    prop_in_vocab = num_test_words_in_vocab / num_test_words_total\n",
    "    prop_not_in_vocab = 1 - prop_in_vocab\n",
    "\n",
    "    print(f\"Proportion of test words in vocab: {prop_in_vocab}\")\n",
    "    print(f\"Proportion of test words not in vocab: {prop_not_in_vocab}\")\n",
    "\n",
    "find_vocab_proportions(num_unique_words_not_in_vocab, num_unique_words_in_vocab, num_test_words_in_vocab, num_test_words_total)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of unique words in vocab: 0.9427178549664839\n",
      "Proportion of unique words not in vocab: 0.05728214503351615\n",
      "Proportion of test words in vocab: 0.9836797957695113\n",
      "Proportion of test words not in vocab: 0.016320204230488744\n"
     ]
    }
   ],
   "execution_count": 1134
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Confidence of Classification (Q3)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.484624Z",
     "start_time": "2025-04-08T15:50:11.479306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For all test instances, divide the posterior likelihoods for each class\n",
    "\n",
    "# Initialise empty lists to store the ratios\n",
    "likelihood_list_c0 = []\n",
    "likelihood_list_c1 =[]\n",
    "\n",
    "# For each test instance, we compute the ratio of the posterior probabilities\n",
    "for post_prob_0, post_prob_1 in zip(c0_posterior, c1_posterior):\n",
    "    likelihood_list_c0.append(post_prob_0 / post_prob_1)\n",
    "    likelihood_list_c1.append(post_prob_1 / post_prob_0)\n",
    "\n",
    "# Find the 3 most confident classifications for c0 (non-malicious)\n",
    "c0_indexes = np.argsort(likelihood_list_c0)[-3:][::-1]\n",
    "c0_ratios = np.sort(likelihood_list_c0)[-3:][::-1]\n",
    "instances_c0 = test_df['textPreprocessed'].iloc[c0_indexes]\n",
    "\n",
    "print(c0_ratios)\n",
    "print(instances_c0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.13499445e+37 2.69038186e+29 3.18292454e+25]\n",
      "341    time : rs. transaction number & & & & & & & & ...\n",
      "223    ? ? ? ? .. .. u u u u , , ... ... ... ... say ...\n",
      "969    . every & & & & & & ; ; ; ; ; ; lt lt lt # # #...\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 1135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.524679Z",
     "start_time": "2025-04-08T15:50:11.520490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the 3 most confident classifications for c1 (malicious)\n",
    "c1_indexes = np.argsort(likelihood_list_c1)[-3:][::-1]\n",
    "c1_ratios = np.sort(likelihood_list_c1)[-3:][::-1]\n",
    "instances_c1 = test_df['textPreprocessed'].iloc[c1_indexes]\n",
    "\n",
    "print(c1_ratios)\n",
    "print(instances_c1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.35388960e+20 1.28709054e+20 1.14912397e+20]\n",
      "844    . 4 + call £ - * holiday & urgent 18 t landlin...\n",
      "985    . 3 4 + ! call : £ offer * holiday & urgent 18...\n",
      "460    . . . , please order text call / : customer to...\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 1136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.566253Z",
     "start_time": "2025-04-08T15:50:11.560961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# On the boundary between the two classes\n",
    "# Find the 3 text instances with R values closest to 1\n",
    "close_to_1_indexes = sorted(range(len(likelihood_list_c0)), key=lambda i: abs(likelihood_list_c0[i] - 1))[:3]\n",
    "close_to_1_ratios = [likelihood_list_c0[i] for i in close_to_1_indexes]\n",
    "\n",
    "instances_close_to_1 = test_df['textPreprocessed'].iloc[close_to_1_indexes]\n",
    "\n",
    "print(close_to_1_ratios)\n",
    "print(instances_close_to_1)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.017098135219966, 1.0441124738285428, 0.9297658433847519]\n",
      "90                  . call dear\n",
      "455                . reply glad\n",
      "767    . . tell return re order\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 1137
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extending the model with semi-supervised training"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Active Learning"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split the labelled data into a training and validation set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.608902Z",
     "start_time": "2025-04-08T15:50:11.604882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sms_df_train = sms_df.sample(frac=0.8, random_state=1462474)\n",
    "sms_df_validation = sms_df.drop(sms_df_train.index)\n"
   ],
   "outputs": [],
   "execution_count": 1138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We must read in the unlabelled data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.656050Z",
     "start_time": "2025-04-08T15:50:11.647086Z"
    }
   },
   "cell_type": "code",
   "source": "sms_unlabelled = pd.read_csv('sms_unlabelled.csv')",
   "outputs": [],
   "execution_count": 1139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.693867Z",
     "start_time": "2025-04-08T15:50:11.689977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we select 200 instances by random\n",
    "sms_ul_sample = sms_unlabelled.sample(200, random_state=1462474)\n",
    "\n",
    "# Append the sampled instances to the training set\n",
    "sms_df_train = pd.concat([sms_df_train, sms_ul_sample], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 1140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.734914Z",
     "start_time": "2025-04-08T15:50:11.728065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess the data\n",
    "sms_df_train = preprocess_data(sms_df_train)\n",
    "sms_df_validation = preprocess_data(sms_df_validation)\n",
    "\n",
    "# For selecting predictive words later\n",
    "sms_unlabelled = preprocess_data(sms_unlabelled)\n"
   ],
   "outputs": [],
   "execution_count": 1141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrain our model on the new training set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:11.810137Z",
     "start_time": "2025-04-08T15:50:11.771024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrains our model by calculating the likelihoods and priors of the new training set\n",
    "def retrain_model(sms_df_train, alpha_new):\n",
    "    # Retrain our model\n",
    "    new_vocab_list = create_vocab_list(sms_df_train)\n",
    "\n",
    "    # Build count matrix\n",
    "    new_count_matrix, new_vocab_dict = build_count_matrix(sms_df_train, new_vocab_list)\n",
    "\n",
    "    # Calculate priors\n",
    "    priors = calculate_priors(sms_df_train)\n",
    "    p_c0_new = priors[0]\n",
    "    p_c1_new = priors[1]\n",
    "    print(priors)\n",
    "\n",
    "    # We need to find the number of times each word appears in each class\n",
    "    count_c0_new = count_words_in_class(0,sms_df_train, new_count_matrix)\n",
    "    count_c1_new = count_words_in_class(1,sms_df_train, new_count_matrix)\n",
    "    print(sum(count_c0_new))\n",
    "    print(sum(count_c0))\n",
    "\n",
    "    # Calculate likelihoods using laplace smoothing\n",
    "    class_0_c_new, class_1_c_new = calculate_likelihoods(count_c0_new, count_c1_new, new_vocab_dict, alpha_new)\n",
    "\n",
    "    return class_0_c_new, class_1_c_new, new_vocab_list, new_vocab_dict\n",
    "\n",
    "# Retrain our model\n",
    "alpha_new = 1\n",
    "class_0_c_new, class_1_c_new, new_vocab_list, new_vocab_dict = retrain_model(sms_df_train, alpha_new)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7966666666666666, 0.20333333333333334]\n",
      "14444.0\n",
      "15861.0\n"
     ]
    }
   ],
   "execution_count": 1142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model is trained now we must evaluate it on our validation set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:12.522794Z",
     "start_time": "2025-04-08T15:50:11.847730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluates our model on the validation set by predicting the labels of each test instance\n",
    "# and calculating the accuracy, confusion matrix, precision and recall\n",
    "def validation_eval(true_labels, class_0_c_new, class_1_c_new, validation_data, new_vocab_list, new_vocab_dict):\n",
    "\n",
    "    # Build the count matrix for the validation set\n",
    "    new_test_count_matrix, num_test_words_in_vocab, num_test_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab = build_test_count_matrix(validation_data, new_vocab_list, new_vocab_dict)\n",
    "\n",
    "    # Count the number of unique words and in the vocab list and test (for question 2)\n",
    "    num_unique_words_in_vocab = len(unique_words_in_vocab)\n",
    "    num_unique_words_not_in_vocab = len(unique_words_not_in_vocab)\n",
    "    num_test_words_total = num_test_words_in_vocab + num_test_words_not_in_vocab\n",
    "\n",
    "    print(num_unique_words_not_in_vocab, num_unique_words_in_vocab, num_test_words_in_vocab, num_test_words_total)\n",
    "\n",
    "    # Class 0 posterior probabilities\n",
    "    c0_posterior = calc_posterior(new_test_count_matrix, class_0_c_new, 0, priors)\n",
    "\n",
    "    # Class 1 posterior probabilities\n",
    "    c1_posterior = calc_posterior(new_test_count_matrix, class_1_c_new, 1, priors)\n",
    "\n",
    "    # Predict the labels\n",
    "    pred_labels, probs = predict_nb(c0_posterior, c1_posterior)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model_eval(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Call the function and evaluate the model\n",
    "validation_eval(sms_df_validation['class'].values, class_0_c_new, class_1_c_new, sms_df_validation, new_vocab_list, new_vocab_dict)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 1065 4208 4292\n",
      "Accuracy: 0.9675\n",
      "Confusion Matrix:\n",
      " [[323   8]\n",
      " [  5  64]]\n",
      "Precision: 0.89\n",
      "Recall: 0.93\n"
     ]
    }
   ],
   "execution_count": 1143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Improving our model: Part 1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:15.463341Z",
     "start_time": "2025-04-08T15:50:12.556983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we must look at the 200 instances added at random to our training set\n",
    "\n",
    "# Using the R value method we used earlier we will find the most predictive words\n",
    "# from our unlabelled data and select the most predictive instances\n",
    "\n",
    "# We will calculate the R value for each instance in the unlabelled data using our original trained model to predict posterior probabilities\n",
    "def unlabelled_predictiveness(sms_unlabelled, vocab_list, vocab_dict, likelihood_lists, priors, n):\n",
    "\n",
    "    # Create a count matrix for the unlabelled data\n",
    "    unlabelled_count_matrix, num_ul_words_in_vocab, num_ul_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab = build_test_count_matrix(sms_unlabelled, vocab_list, vocab_dict)\n",
    "\n",
    "\n",
    "    # Find the posterior probabilities for each class\n",
    "    unlabelled_class_0_posteriors = calc_posterior(unlabelled_count_matrix, likelihood_lists[0], 0, priors)\n",
    "    unlabelled_class_1_posteriors = calc_posterior(unlabelled_count_matrix, likelihood_lists[1], 1, priors)\n",
    "\n",
    "\n",
    "    # Calculate the R value for each instance\n",
    "\n",
    "    # Initialise empty lists to store the R values\n",
    "    ul_r_0 = []\n",
    "    ul_r_1 = []\n",
    "\n",
    "    for i in range(len(unlabelled_count_matrix)):\n",
    "        # Find the R values for each instance\n",
    "        ul_r_0.append(unlabelled_class_0_posteriors[i] / unlabelled_class_1_posteriors[i])\n",
    "        ul_r_1.append(unlabelled_class_1_posteriors[i] / unlabelled_class_0_posteriors[i])\n",
    "\n",
    "    \"\"\"\" Using our priors we split n (200) into the two classes, keeping the ratio of our classes as close as possible to the test data\n",
    "    # For class 0 we should include\n",
    "    n_c0 = int(n * priors[0])\n",
    "    # Ensure the total adds up to n (200)\n",
    "    n_c1 = n - n_c0\n",
    "\n",
    "    # Find the indexes of the n_c0 most predictive instances for class 0\n",
    "\n",
    "    c0_ul_indexes = np.argsort(ul_r_0)[-n_c0:][::-1]\n",
    "    c0_ul_ratios = np.sort(ul_r_0)[-n_c0:][::-1]\n",
    "\n",
    "    # Return the n_c0 most predictive instances\n",
    "    instances_ul_c0 = sms_unlabelled.iloc[c0_ul_indexes]\n",
    "\n",
    "    # Find the indexes of the n_c1 most predictive instances for class 1\n",
    "    c1_ul_indexes = np.argsort(ul_r_1)[-n_c1:][::-1]\n",
    "    c1_ul_ratios = np.sort(ul_r_1)[-n_c1:][::-1]\n",
    "\n",
    "    # Return the n_c1 most predictive instances\n",
    "    instances_ul_c1 = sms_unlabelled.iloc[c1_ul_indexes] \"\"\"\n",
    "\n",
    "    # Choosing the highest R values didn't work so we will choose the R values closest to 1\n",
    "    close_to_1_indexes_ul = sorted(range(len(ul_r_0)), key=lambda i: abs(ul_r_0[i] - 1))[:n]\n",
    "    close_to_1_ratios_ul = [ul_r_0[i] for i in close_to_1_indexes_ul]\n",
    "    instances_close_to_1 = sms_unlabelled.iloc[close_to_1_indexes_ul]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Class 0 R values:\", close_to_1_ratios_ul[0:10])\n",
    "\n",
    "    return instances_close_to_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find the 200 most predictive instances\n",
    "n = 200\n",
    "# Use the original trained model and priors to predict the posterior probabilities and get the predictive instances\n",
    "instances_to_add = unlabelled_predictiveness(sms_unlabelled, vocab_list, vocab_dict, [class_0_c, class_1_c], priors, n)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 R values: [0.9919068501371178, 1.0391099885844937, 1.0562412674534627, 0.931172550358091, 1.069380585834582, 0.8350516704209388, 0.8159411980807586, 1.1892374257663776, 0.8070164023707342, 0.7783702940242561]\n"
     ]
    }
   ],
   "execution_count": 1144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Retrain model using these 200 words instead"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:16.128499Z",
     "start_time": "2025-04-08T15:50:15.540936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reread in the training set and append the new instances\n",
    "# Add the new instances to the training set\n",
    "\n",
    "sms_df = pd.read_csv(\"sms_supervised_train.csv\")\n",
    "\n",
    "# Split the labelled data into a training and validation set\n",
    "sms_df_improved_train = sms_df.sample(frac=0.8, random_state=1462474)\n",
    "sms_df_improved_validation = sms_df.drop(sms_df_improved_train.index)\n",
    "\n",
    "\n",
    "print(len(sms_df_improved_train))\n",
    "print(len(sms_df_improved_validation))\n",
    "\n",
    "# Now we follow what we did earlier and retrain our model\n",
    "\n",
    "# Append the sampled instances to the training set\n",
    "sms_df_improved_train = pd.concat([sms_df_improved_train, instances_to_add], ignore_index=True)\n",
    "sms_df_improved_train = sms_df_improved_train.reset_index(drop=True)\n",
    "\n",
    "# Preprocess the data\n",
    "sms_df_improved_train = preprocess_data(sms_df_improved_train)\n",
    "sms_df_improved_validation = preprocess_data(sms_df_improved_validation)\n",
    "\n",
    "alpha_improved = 1\n",
    "class_0_c_new_i, class_1_c_new_i, new_vocab_list_i, new_vocab_dict_i = retrain_model(sms_df_improved_train, alpha_improved)\n",
    "\n",
    "validation_eval(sms_df_improved_validation['class'].values, class_0_c_new_i,\n",
    "                class_1_c_new_i, sms_df_improved_validation, new_vocab_list_i, new_vocab_dict_i)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "400\n",
      "[0.7333333333333333, 0.26666666666666666]\n",
      "13231.0\n",
      "15861.0\n",
      "63 1062 4207 4292\n",
      "Accuracy: 0.9725\n",
      "Confusion Matrix:\n",
      " [[323   8]\n",
      " [  3  66]]\n",
      "Precision: 0.89\n",
      "Recall: 0.96\n"
     ]
    }
   ],
   "execution_count": 1145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:16.169022Z",
     "start_time": "2025-04-08T15:50:16.166900Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test model on test data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:16.207451Z",
     "start_time": "2025-04-08T15:50:16.205652Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:16.282540Z",
     "start_time": "2025-04-08T15:50:16.280023Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:50:16.300259Z",
     "start_time": "2025-04-08T15:50:16.298501Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
