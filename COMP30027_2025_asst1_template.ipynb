{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2025 Semester 1\n",
    "\n",
    "## Assignment 1: Scam detection with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Student ID(s):**     `1462474`\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, GRAPHS, AND FIGURES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).** Results, figures, etc. which appear in this file but are NOT included in your report will not be marked.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised model training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:34:12.683807Z",
     "start_time": "2025-04-08T07:34:11.673714Z"
    }
   },
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Read in supervised training dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:34:12.735544Z",
     "start_time": "2025-04-08T07:34:12.698367Z"
    }
   },
   "cell_type": "code",
   "source": "sms_df = pd.read_csv('sms_supervised_train.csv')",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reformat text to help with tokenising"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:35:34.501076Z",
     "start_time": "2025-04-08T07:35:34.456666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensures data types are as intended and no nulls\n",
    "def preprocess_data(df):\n",
    "    df['textPreprocessed'] = df['textPreprocessed'].astype(str)\n",
    "    df = df.dropna(subset=['textPreprocessed'])\n",
    "    df['class'] = df['class'].astype(int)\n",
    "    return df\n",
    "\n",
    "sms_df = preprocess_data(sms_df)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Build vocabulary list"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:35:39.036752Z",
     "start_time": "2025-04-08T07:35:39.023968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define vocab list (set for build efficiency)\n",
    "vocab_set = set()\n",
    "\n",
    "# For each row in the dataset, split text into words and add them to the vocab set\n",
    "# Convert to a list at the end\n",
    "def create_vocab_list(df):\n",
    "    vocab_set = set()\n",
    "    for text in df['textPreprocessed']:\n",
    "        words = text.split()\n",
    "        vocab_set.update(words)\n",
    "    return list(vocab_set)\n",
    "\n",
    "# Create vocab list\n",
    "vocab_list = create_vocab_list(sms_df)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Build count matrix"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:38:25.561078Z",
     "start_time": "2025-04-08T07:38:25.519067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates a count matrix where each row represents a text instance\n",
    "# Columns represent the words in the vocab list.\n",
    "# Returns the matrix and a dictionary mapping words to their index in the vocab list\n",
    "def build_count_matrix(df, vocab_list):\n",
    "    # Initialise empty count matrix\n",
    "    count_matrix = np.zeros((df.shape[0], len(vocab_list)))\n",
    "    # Create dictionary mapping words to their index in the vocab list\n",
    "    vocab_dict = {word: i for i, word in enumerate(vocab_list)}\n",
    "    for index, text in df['textPreprocessed'].items():\n",
    "        for word in text.split():\n",
    "            # If the word is in the vocab list, increment its count in the matrix\n",
    "            if word in vocab_dict:\n",
    "                word_index = vocab_dict.get(word)\n",
    "                count_matrix[index][word_index] += 1\n",
    "    return count_matrix, vocab_dict\n",
    "\n",
    "# Build count matrix\n",
    "count_matrix,vocab_dict = build_count_matrix(sms_df, vocab_list)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute the prior probability of each class:\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:38:27.203895Z",
     "start_time": "2025-04-08T07:38:27.192397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the prior probability of each class given the dataframe\n",
    "def calculate_priors(df):\n",
    "    n_rows = df.shape[0]\n",
    "    # Count the number of instances in each class\n",
    "    n_c0 = df[df['class'] == 0].shape[0]\n",
    "    n_c1 = df[df['class'] == 1].shape[0]\n",
    "    # Calculate the prior probability of each class\n",
    "    p_c0 = n_c0 / n_rows\n",
    "    p_c1 = n_c1 / n_rows\n",
    "    return [p_c0, p_c1]\n",
    "\n",
    "# Calculate priors\n",
    "priors = calculate_priors(sms_df)\n",
    "p_c0 = priors[0]\n",
    "p_c1 = priors[1]\n",
    "\n",
    "# Answer to question 1 in our report\n",
    "print(f\"Our two priors are p_c0 = {p_c0}\\nand p_c1 = {p_c1} \")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our two priors are p_c0 = 0.8\n",
      "and p_c1 = 0.2 \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Find the probability of each word appearing in a message from each class (likelihood)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T07:38:29.950016Z",
     "start_time": "2025-04-08T07:38:29.923063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we need to find the number of times each word appears in each class\n",
    "\n",
    "''' Counts the number of times each word appears in a given class\n",
    "    returns an list of counts '''\n",
    "def count_words_in_class(class_num):\n",
    "    # Find the indexes of the rows in the count matrix that belong to the given class\n",
    "    index_list = np.where(sms_df['class'] == class_num)[0]\n",
    "    # Get the count matrix for the given class (only shows rows where we classify as class_num)\n",
    "    class_count_matrix = count_matrix[index_list]\n",
    "    # Sums the word counts across all text instances for the class\n",
    "    count_list = class_count_matrix.sum(axis=0)\n",
    "    return count_list\n",
    "\n",
    "# Class 0 count\n",
    "count_c0 = count_words_in_class(0)\n",
    "\n",
    "# Class 1 count\n",
    "count_c1 = count_words_in_class(1)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:40.789370Z",
     "start_time": "2025-04-07T14:26:40.782621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We will use laplace smoothing to ensure every event has a non-zero probability\n",
    "# Since we have sparse data (more on report)\n",
    "\n",
    "# Laplace smoothing value\n",
    "alpha = 1\n",
    "\n",
    "# Laplace function returns the conditional probability of a word given a class\n",
    "# with laplace smoothing\n",
    "def laplace(count, alpha, total, v):\n",
    "    return (count+alpha) / (total + v*alpha)\n",
    "\n",
    "# Calculates the likelihoods p_(c,i) of word i appearing in a given class c\n",
    "# returns the probability lists for each word in the vocab list and each class\n",
    "def calculate_likelihoods(count_c0, count_c1, vocab_dict, alpha=1):\n",
    "    # Initialise empty lists to store the likelihoods\n",
    "    class_0_c = []\n",
    "    class_1_c = []\n",
    "    # Calculate total count of words in each class\n",
    "    total_c0 = count_c0.sum()\n",
    "    total_c1 = count_c1.sum()\n",
    "    # Find the length of the vocab list\n",
    "    V = len(vocab_dict)\n",
    "    # For each class calculate the likelihood list\n",
    "    for word, index in vocab_dict.items():\n",
    "        count = count_c0[index]\n",
    "        # Find prob using laplace smoothing\n",
    "        p_ci = laplace(count, alpha, total_c0, V)\n",
    "        class_0_c.append(p_ci)\n",
    "    for word, index in vocab_dict.items():\n",
    "        count = count_c1[index]\n",
    "        # Find prob using laplace smoothing\n",
    "        p_ci = laplace(count, alpha, total_c1, V)\n",
    "        class_1_c.append(p_ci)\n",
    "    return class_0_c, class_1_c\n",
    "\n",
    "# Find the likelihoods for each class\n",
    "class_0_c, class_1_c = calculate_likelihoods(count_c0, count_c1, vocab_dict, alpha)\n",
    "\n",
    "\n",
    "# Check probabilities sum to roughly one\n",
    "print(sum(class_1_c))\n",
    "print(sum(class_0_c))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999745\n",
      "1.0000000000000047\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Further supervised model training questions for report"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:43.214077Z",
     "start_time": "2025-04-07T14:26:43.207824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Question 2\n",
    "# Find the most probable words in each class\n",
    "\n",
    "# We find the 10 most probable words by sorting the probabilities list\n",
    "# and finding their indexes in the original vocab list\n",
    "\n",
    "'''Finds and returns the n most probable words in a given class\n",
    "    returns a list in order of probability (descending) and a list\n",
    "     containing their probability values'''\n",
    "def find_n_most_probable(n, class_num):\n",
    "    # Find the count list for the given class\n",
    "    if class_num == 0:\n",
    "        prob_list = class_0_c\n",
    "    elif class_num == 1:\n",
    "        prob_list = class_1_c\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    # Sort the list and get the indexes of the n most probable words\n",
    "    sorted_indexes = np.argsort(prob_list)[-n:][::-1]\n",
    "\n",
    "    sorted_probs = np.sort(prob_list)[-n:][::-1]\n",
    "\n",
    "    # Get the words from our vocab list using the indexes\n",
    "    most_probable_words = [vocab_list[i] for i in sorted_indexes]\n",
    "\n",
    "    return most_probable_words, sorted_probs\n",
    "\n",
    "\n",
    "# Find the 10 most probable words in class 0\n",
    "print(\"Most probable words in class 0:\", find_n_most_probable(10, 0)[0])\n",
    "\n",
    "# List their probability values\n",
    "print(\"Probability values for class 0:\", find_n_most_probable(10, 0)[1])\n",
    "\n",
    "# Find the 10 most probable words in class 1\n",
    "print(\"Most probable words in class 1:\", find_n_most_probable(10, 1)[0])\n",
    "print(\"Probability values for class 1:\", find_n_most_probable(10, 1)[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable words in class 0: ['.', ',', '?', 'u', '...', '!', '..', ';', '&', 'go']\n",
      "Probability values for class 0: [0.07930378 0.02602418 0.02557645 0.0189165  0.0187486  0.01718155\n",
      " 0.01494291 0.013152   0.01309604 0.01113723]\n",
      "Most probable words in class 1: ['.', '!', ',', 'call', '£', 'free', '/', '2', '&', '?']\n",
      "Probability values for class 1: [0.05652174 0.02434783 0.02347826 0.02054348 0.01391304 0.01054348\n",
      " 0.00913043 0.00880435 0.00869565 0.00847826]\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Question 3: Finding the most predictive words\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:46.817191Z",
     "start_time": "2025-04-07T14:26:46.811076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the probability ratio of a word occurring in class 0 vs class 1\n",
    "class_0_c = np.array(class_0_c)\n",
    "class_1_c = np.array(class_1_c)\n",
    "p_ratio_non_mal = class_0_c/class_1_c\n",
    "\n",
    "# We don't have to worry about dividing by zero as we have already applied laplace smoothing\n",
    "\n",
    "# Find the 10 most strongly predictive words of the non-malicious class\n",
    "sorted_c0_div_c1 = np.argsort(p_ratio_non_mal)[-10:][::-1]\n",
    "most_predictive_words_non_mal = [vocab_list[i] for i in sorted_c0_div_c1]\n",
    "non_scam_ratios = np.sort(p_ratio_non_mal)[-10:][::-1]\n",
    "\n",
    "# Find the 10 most strongly predictive words of the malicious class\n",
    "p_ratio_mal = class_1_c/class_0_c\n",
    "sorted_c1_div_c0 = np.argsort(p_ratio_mal)[-10:][::-1]\n",
    "most_predictive_words_mal = [vocab_list[i] for i in sorted_c1_div_c0]\n",
    "scam_ratios = np.sort(p_ratio_mal)[-10:][::-1]\n",
    "\n",
    "# Print the most predictive words of the non-malicious class\n",
    "print(\"The most predictive words of the non-malicious class are:\", most_predictive_words_non_mal)\n",
    "print(\"The associated probability ratios are:\", non_scam_ratios)\n",
    "\n",
    "\n",
    "\n",
    "# Print the most predictive words of the malicious class\n",
    "print(\"The most predictive words of the malicious class are:\", most_predictive_words_mal)\n",
    "print(\"The associated probability ratios are:\", scam_ratios)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most predictive words of the non-malicious class are: [';', '...', 'gt', 'lt', ':)', 'ü', 'lor', 'ok', 'hope', 'd']\n",
      "The associated probability ratios are: [60.49921648 57.49570928 54.06312962 53.54824267 47.88448623 31.92299082\n",
      " 28.83366913 24.71457354 24.71457354 21.1103649 ]\n",
      "The most predictive words of the malicious class are: ['prize', 'tone', '£', 'select', 'claim', 'paytm', 'code', 'award', 'won', '18']\n",
      "The associated probability ratios are: [99.05086957 64.09173913 49.71965217 46.61217391 45.96478261 36.90130435\n",
      " 34.95913043 32.04586957 31.07478261 29.1326087 ]\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Supervised model evaluation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting the labels of our test set"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:53.206196Z",
     "start_time": "2025-04-07T14:26:53.199719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in our test dataset\n",
    "test_df = pd.read_csv('sms_test.csv')\n"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:54.388656Z",
     "start_time": "2025-04-07T14:26:54.381824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the same preprocessing steps as before\n",
    "# Ensure all values in the column are strings\n",
    "test_df['textPreprocessed'] = test_df['textPreprocessed'].astype(str)\n",
    "\n",
    "# Ensure no null values affect tokenising\n",
    "# Find num rows\n",
    "test_rows = test_df.shape[0]\n",
    "print(\"Number of entries before dropping null values: \", test_rows)\n",
    "test_df = test_df.dropna(subset=['textPreprocessed'])\n",
    "print(\"Number of entries before after dropping null values: \", test_rows)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries before dropping null values:  1000\n",
      "Number of entries before after dropping null values:  1000\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:26:57.073853Z",
     "start_time": "2025-04-07T14:26:57.056428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each test instance, compute a count vector\n",
    "# which represents the number of times each word in the vocab list appears\n",
    "# This will be in the form of an N_test x V matrix\n",
    "def build_test_count_matrix(df, vocab_list, vocab_dict):\n",
    "    # Initialise empty count matrix\n",
    "    test_count_matrix = np.zeros((df.shape[0], len(vocab_list)))\n",
    "    # Counters and sets for question 2\n",
    "    unique_words_in_vocab = set()\n",
    "    unique_words_not_in_vocab = set()\n",
    "    num_test_words_in_vocab = 0\n",
    "    num_test_words_not_in_vocab = 0\n",
    "\n",
    "    # Add words that exist in our vocab to the new count matrix for each row in the data\n",
    "    for index, text in df['textPreprocessed'].items():\n",
    "        for word in text.split():\n",
    "            if word in vocab_dict:\n",
    "                word_index = vocab_dict.get(word)\n",
    "                test_count_matrix[index][word_index] += 1\n",
    "                unique_words_in_vocab.add(word)\n",
    "                num_test_words_in_vocab += 1\n",
    "            else:\n",
    "                unique_words_not_in_vocab.add(word)\n",
    "                num_test_words_not_in_vocab += 1\n",
    "\n",
    "    return test_count_matrix, num_test_words_in_vocab, num_test_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab\n",
    "\n",
    "\n",
    "\n",
    "# Build the test count matrix\n",
    "test_count_matrix, num_test_words_in_vocab, num_test_words_not_in_vocab, unique_words_in_vocab, unique_words_not_in_vocab = build_test_count_matrix(test_df, vocab_list, vocab_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of unique words and in the vocab list and test (for question 2)\n",
    "num_unique_words_in_vocab = len(unique_words_in_vocab)\n",
    "num_unique_words_not_in_vocab = len(unique_words_not_in_vocab)\n",
    "num_test_words_total = num_test_words_in_vocab + num_test_words_not_in_vocab\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:27:00.890490Z",
     "start_time": "2025-04-07T14:27:00.882229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if all test instances contain words from the vocab list\n",
    "# If an instance contains no words from the vocab list, we won't classify it\n",
    "\n",
    "for row in test_count_matrix:\n",
    "    if row.sum() == 0:\n",
    "        print(\"Found a row with no words from the vocab list\")\n",
    "        print(row)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "No test items skipped as this code does not output any rows (refer to q2 below)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute the posterior probability of each class given the observed word count"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:27:03.884921Z",
     "start_time": "2025-04-07T14:27:02.274600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each test instance, we compute the posterior probability of observing each\n",
    "# word given the class label\n",
    "def calc_posterior(count_matrix, likelihoods_list, label_index):\n",
    "    # Initialise empty list to store posterior probabilities\n",
    "    posterior_probs = []\n",
    "\n",
    "    prior_value = priors[label_index]\n",
    "\n",
    "    # For each test instance\n",
    "    for row in count_matrix:\n",
    "        # Initialise posterior probability\n",
    "        posterior = np.log(prior_value)\n",
    "\n",
    "        # For each word in the vocab list\n",
    "        for i, word_freq in enumerate(row):\n",
    "            if word_freq > 0:\n",
    "                # Get the likelihood of the word given the class label\n",
    "                likelihood_value = likelihoods_list[i]\n",
    "\n",
    "                # Take the log of this value to combat overflow\n",
    "                log_likelihood_value = np.log(likelihood_value)\n",
    "\n",
    "\n",
    "                # Update the posterior probability\n",
    "                posterior += (log_likelihood_value * word_freq)\n",
    "\n",
    "\n",
    "        # Find the log multinomial coefficient\n",
    "        # Using log gamma function to avoid overflow\n",
    "        log_multinomial_coefficient = (\n",
    "            math.lgamma(row.sum() + 1) - np.sum([math.lgamma(c + 1) for c in row])\n",
    "        )\n",
    "\n",
    "        posterior += log_multinomial_coefficient\n",
    "\n",
    "        # Take the exponent of the posterior probability\n",
    "        posterior = np.exp(posterior)\n",
    "\n",
    "\n",
    "        # Add the posterior probability to our list\n",
    "        posterior_probs.append(posterior)\n",
    "    return posterior_probs\n",
    "\n",
    "# Class 0 posterior\n",
    "c0_posterior = calc_posterior(test_count_matrix, class_0_c, 0)\n",
    "\n",
    "# Class 1 posterior\n",
    "\n",
    "c1_posterior = calc_posterior(test_count_matrix, class_1_c, 1)\n",
    "\n",
    "\n",
    "print(max(c1_posterior))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011304347826086959\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Predict the labels of each test instance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:27:05.301542Z",
     "start_time": "2025-04-07T14:27:05.297596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Predicts the labels of each test instance using the posterior probabilities '''\n",
    "def predict_nb(c0_posterior, c1_posterior):\n",
    "\n",
    "    # Using our previously calculated posterior probabilities:\n",
    "\n",
    "    # Find argmax for each instance\n",
    "    argmax_labels = []\n",
    "    associated_probs = []\n",
    "\n",
    "    for post_prob_0, post_prob_1 in zip(c0_posterior, c1_posterior):\n",
    "        # Find the maximum posterior probability\n",
    "        if post_prob_0 >= post_prob_1:\n",
    "            associated_probs.append(post_prob_0)\n",
    "            argmax_labels.append(0)\n",
    "\n",
    "        # Otherwise if probabilities are less we classify as 1 (we use >= above to ensure we don't misclassify important messages)\n",
    "        else:\n",
    "            associated_probs.append(post_prob_1)\n",
    "            argmax_labels.append(1)\n",
    "\n",
    "    return argmax_labels, associated_probs\n",
    "\n",
    "\n",
    "# Run on our dataset\n",
    "pred_labels, probs = predict_nb(c0_posterior, c1_posterior)\n",
    "\n",
    "print(pred_labels[1:20])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Find the accuracy of our model (Q1)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:41:10.008076Z",
     "start_time": "2025-04-07T14:41:10.001460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Overall accuracy of our classifier\n",
    "\n",
    "def get_accuracy(labels, true_labels):\n",
    "    # Find the number of correct predictions\n",
    "    num_correct = np.sum(labels == true_labels)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = num_correct / len(true_labels)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_df['class'].values\n",
    "\n",
    "# Prints the accuracy, confusion matrix, precision and recall\n",
    "# of our model's predictions\n",
    "def model_eval(true_labels, pred_labels):\n",
    "    accuracy = get_accuracy(true_labels, pred_labels)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusion_matrix = np.zeros((2, 2), dtype=int)\n",
    "    # Fill the confusion matrix\n",
    "    for true, predicted in zip(true_labels, pred_labels):\n",
    "        confusion_matrix[true][predicted] += 1\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "    TN = confusion_matrix[0, 0]\n",
    "    FP = confusion_matrix[0, 1]\n",
    "    FN = confusion_matrix[1, 0]\n",
    "    TP = confusion_matrix[1, 1]\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Evaluate our model\n",
    "model_eval(true_labels, pred_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n",
      "Confusion Matrix:\n",
      " [[785  15]\n",
      " [ 10 190]]\n",
      "Precision: 0.93\n",
      "Recall: 0.95\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### How often we encountered out of vocab words (Q2)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:46:38.446997Z",
     "start_time": "2025-04-07T14:46:38.442644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_vocab_proportions(num_unique_words_not_in_vocab, num_unique_words_in_vocab, num_test_words_in_vocab, num_test_words_total):\n",
    "    # Proportion of unique words in the test set that were not in the vocab list\n",
    "    prop_unique_not_in_vocab = num_unique_words_not_in_vocab / (num_unique_words_not_in_vocab + num_unique_words_in_vocab)\n",
    "    prop_unique_in_vocab = 1 - prop_unique_not_in_vocab\n",
    "\n",
    "    print(f\"Proportion of unique words in vocab: {prop_unique_in_vocab}\")\n",
    "    print(f\"Proportion of unique words not in vocab: {prop_unique_not_in_vocab}\")\n",
    "\n",
    "    # Proportion of words in the test set that were not in the vocab list\n",
    "    prop_in_vocab = num_test_words_in_vocab / num_test_words_total\n",
    "    prop_not_in_vocab = 1 - prop_in_vocab\n",
    "\n",
    "    print(f\"Proportion of test words in vocab: {prop_in_vocab}\")\n",
    "    print(f\"Proportion of test words not in vocab: {prop_not_in_vocab}\")\n",
    "\n",
    "find_vocab_proportions(num_unique_words_not_in_vocab, num_unique_words_in_vocab, num_test_words_in_vocab, num_test_words_total)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of unique words in vocab: 0.9427178549664839\n",
      "Proportion of unique words not in vocab: 0.05728214503351615\n",
      "Proportion of test words in vocab: 0.9836797957695113\n",
      "Proportion of test words not in vocab: 0.016320204230488744\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Confidence of Classification (Q3)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:28:04.112305Z",
     "start_time": "2025-04-07T12:28:04.105782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For all test instances, divide the posterior likelihoods for each class\n",
    "\n",
    "likelihood_list_c0 = []\n",
    "likelihood_list_c1 =[]\n",
    "\n",
    "# For each test instance, we compute the ratio of the posterior probabilities\n",
    "for post_prob_0, post_prob_1 in zip(c0_posterior, c1_posterior):\n",
    "    likelihood_list_c0.append(post_prob_0 / post_prob_1)\n",
    "    likelihood_list_c1.append(post_prob_1 / post_prob_0)\n",
    "\n",
    "# Find the 3 most confident classifications for c0 (non-malicious)\n",
    "c0_indexes = np.argsort(likelihood_list_c0)[-3:][::-1]\n",
    "c0_ratios = np.sort(likelihood_list_c0)[-3:][::-1]\n",
    "instances_c0 = test_df['textPreprocessed'].iloc[c0_indexes]\n",
    "\n",
    "print(c0_ratios)\n",
    "print(instances_c0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.13499445e+37 2.69038186e+29 3.18292454e+25]\n",
      "341    time : rs. transaction number & & & & & & & & ...\n",
      "223    ? ? ? ? .. .. u u u u , , ... ... ... ... say ...\n",
      "969    . every & & & & & & ; ; ; ; ; ; lt lt lt # # #...\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:28:05.659177Z",
     "start_time": "2025-04-07T12:28:05.655103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the 3 most confident classifications for c1 (malicious)\n",
    "c1_indexes = np.argsort(likelihood_list_c1)[-3:][::-1]\n",
    "c1_ratios = np.sort(likelihood_list_c1)[-3:][::-1]\n",
    "instances_c1 = test_df['textPreprocessed'].iloc[c1_indexes]\n",
    "\n",
    "print(c1_ratios)\n",
    "print(instances_c1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.35388960e+20 1.28709054e+20 1.14912397e+20]\n",
      "844    . 4 + call £ - * holiday & urgent 18 t landlin...\n",
      "985    . 3 4 + ! call : £ offer * holiday & urgent 18...\n",
      "460    . . . , please order text call / : customer to...\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:28:37.901650Z",
     "start_time": "2025-04-07T12:28:37.896288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# On the boundary between the two classes\n",
    "# Find the 3 text instances with R values closest to 1\n",
    "close_to_1_indexes = sorted(range(len(likelihood_list_c0)), key=lambda i: abs(likelihood_list_c0[i] - 1))[:3]\n",
    "close_to_1_ratios = [likelihood_list_c0[i] for i in close_to_1_indexes]\n",
    "\n",
    "instances_close_to_1 = test_df['textPreprocessed'].iloc[close_to_1_indexes]\n",
    "\n",
    "print(close_to_1_ratios)\n",
    "print(instances_close_to_1)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0170981352199624, 1.0441124738285466, 0.9297658433847452]\n",
      "90                  . call dear\n",
      "455                . reply glad\n",
      "767    . . tell return re order\n",
      "Name: textPreprocessed, dtype: object\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extending the model with semi-supervised training"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Active Learning"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split the labelled data into a training and validation set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:49:21.743340Z",
     "start_time": "2025-04-07T14:49:21.738619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sms_df_train = sms_df.sample(frac=0.8, random_state=1462474)\n",
    "sms_df_validation = sms_df.drop(sms_df_train.index)"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We must read in the unlabelled data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:49:22.378352Z",
     "start_time": "2025-04-07T14:49:22.368840Z"
    }
   },
   "source": "sms_unlabelled = pd.read_csv('sms_unlabelled.csv')",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:49:22.945868Z",
     "start_time": "2025-04-07T14:49:22.940997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we select 200 instances by random\n",
    "sms_ul_sample = sms_unlabelled.sample(200, random_state=1462474)\n",
    "\n",
    "# Append the sampled instances to the training set\n",
    "sms_df_train = pd.concat([sms_df_train, sms_ul_sample], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:49:24.011040Z",
     "start_time": "2025-04-07T14:49:24.003813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess the data\n",
    "sms_df_train = preprocess_data(sms_df_train)\n",
    "sms_df_validation = preprocess_data(sms_df_validation)\n"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrain our model on the new training set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:49:55.060080Z",
     "start_time": "2025-04-07T14:49:55.032288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrain our model\n",
    "\n",
    "new_vocab_list = create_vocab_list(sms_df_train)\n",
    "# Initialise empty count matrix\n",
    "\n",
    "# Build count matrix\n",
    "new_count_matrix, new_vocab_dict = build_count_matrix(sms_df_train, new_vocab_list)\n",
    "\n",
    "\n",
    "# Calculate priors\n",
    "priors = calculate_priors(sms_df_train)\n",
    "p_c0_new = priors[0]\n",
    "p_c1_new = priors[1]\n",
    "\n",
    "print(priors)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7966666666666666, 0.20333333333333334]\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:50:17.068350Z",
     "start_time": "2025-04-07T14:50:17.049636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate likelihoods using laplace smoothing\n",
    "count_c0_new = count_words_in_class(0)\n",
    "count_c1_new = count_words_in_class(1)\n",
    "class_0_c_new, class_1_c_new = calculate_likelihoods(count_c0_new, count_c1_new, new_vocab_dict, alpha)"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model is trained now we must evaluate it on our validation set"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "_"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T13:25:26.382248Z",
     "start_time": "2025-03-31T13:25:26.379309Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:25:26.538886Z",
     "start_time": "2025-03-31T13:25:26.535733Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
